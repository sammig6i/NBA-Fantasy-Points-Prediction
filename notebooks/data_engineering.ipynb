{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries and settings\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import unicodedata\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib as plt\n",
    "%config InlineBackend.figure_format ='retina'\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from requests.exceptions import HTTPError\n",
    "from variables import team_dictionary, month_dictionary, month_list\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Capture box scores for each NBA game played in the 22-23 and 23-24 seasons\n",
    "We will look at the schedule of every game on BBref and save the box score urls to get the stats of every player"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Function - Links for Calendar Month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first fetch the month links\n",
    "def get_month_links(start_url):\n",
    "  base_url = 'https://www.basketball-reference.com'\n",
    "  month_link_list = []\n",
    "  try:\n",
    "    response = requests.get(start_url)\n",
    "    response.raise_for_status()\n",
    "  except requests.exceptions.HTTPError as err:\n",
    "    if response.status_code == 429:\n",
    "      print(\"Rate limit exceeded. Please try again later.\")\n",
    "    else:\n",
    "      print(f\"HTTP error occurred: {err}\")\n",
    "    return None, None\n",
    "  \n",
    "  soup = BeautifulSoup(response.text, 'html.parser')\n",
    "  season = soup.find('h1').text\n",
    "  season = season.strip().split(' ')\n",
    "  season = season[0]\n",
    "  body = soup.find('body')\n",
    "  div_elements = body.find_all('div', class_='filter')\n",
    "  for div in div_elements:\n",
    "    a_tags = div.find_all('a', href=True)\n",
    "    for a_tag in a_tags:\n",
    "        link_text = a_tag.text.strip().lower()\n",
    "        if link_text in month_list:\n",
    "            month_link_list.append((link_text, f\"{base_url}{a_tag['href']}\"))\n",
    "  return month_link_list, season"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Function - Links for each Box Score and Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_box_score_links(month_link_list):\n",
    "  base_url = 'https://www.basketball-reference.com'\n",
    "  page_to_check_dict = {'Month': [], 'Url': [], 'Index': []}\n",
    "  box_link_array = []\n",
    "  all_dates = []\n",
    "\n",
    "\n",
    "  for month, page in month_link_list:\n",
    "    page_link_list = []\n",
    "    page_date_list = []\n",
    "    try:\n",
    "      response = requests.get(page)\n",
    "      response.raise_for_status()\n",
    "      soup = BeautifulSoup(response.text, 'html.parser')\n",
    "      table = soup.find_all('tbody')\n",
    "      box_scores = table[0].find_all('a', href=True)\n",
    "      for i in box_scores:\n",
    "        if i.text.strip() == 'Box Score':\n",
    "            page_link_list.append(f'{base_url}{i['href']}')\n",
    "        if ',' in i.text.strip():\n",
    "            date = i.text.strip()\n",
    "            date = date.split(', ')\n",
    "            year = date[2]\n",
    "            date = date[1].split(' ')\n",
    "            day = f'0{date[1]}' if len(date[1]) == 1 else date[1]\n",
    "\n",
    "            mon = month_dictionary[date[0]]\n",
    "            date = f'{year}{mon}{day}'\n",
    "            page_date_list.append(date)\n",
    "      if len(page_link_list) == 0 or len(box_scores)/len(page_link_list) != 4:\n",
    "          page_to_check_dict['Url'].append(page)\n",
    "          page_to_check_dict['Month'].append(month)\n",
    "          page_to_check_dict['Index'].append(len(page_link_list))\n",
    "      else:\n",
    "          page_to_check_dict['Url'].append(page)\n",
    "          page_to_check_dict['Month'].append(month)\n",
    "          page_to_check_dict['Index'].append(None)\n",
    "      box_link_array.append(page_link_list)\n",
    "      all_dates.append(page_date_list)\n",
    "      time.sleep(10)\n",
    "    except HTTPError as err:\n",
    "      if response.status_code == 429:\n",
    "        print(\"Rate limit exceeded. Please try again later.\")\n",
    "      else:\n",
    "        print(f\"HTTP error occurred: {err}\")\n",
    "      return None, None\n",
    "  return box_link_array, all_dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Function - Extract player stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate through the box links and dates and extract game data for each player\n",
    "# from https://medium.com/@HeeebsInc/using-machine-learning-to-predict-daily-fantasy-basketball-scores-part-i-811de3c54a98\n",
    "def extract_player_data(box_links, all_dates, season):\n",
    "  df_columns = ['Date', 'Name', 'Team', 'MP', 'FG', 'FGA', 'FG%', '3P', '3PA',\n",
    "               '3P%','FT', 'FTA', 'FT%', 'ORB','DRB', 'TRB', 'AST', 'STL', 'BLK', \n",
    "               'TOV', 'PF', 'PTS', 'GmSc', '+-' ]\n",
    "  stat_df = pd.DataFrame(columns = df_columns)\n",
    "  error_df = pd.DataFrame(columns = ['URL', 'Error'])\n",
    "  for i, (l, d) in enumerate(zip(box_links, all_dates)):\n",
    "    print(f'Processing batch {i+1}/{len(box_links)}')\n",
    "    for link, date in zip(l, d):\n",
    "      print(f'{link}\\n{date}')\n",
    "      print(f'Currently Scraping {link}')\n",
    "      \n",
    "      try:\n",
    "        response = requests.get(link)\n",
    "        response.raise_for_status()\n",
    "        response.encoding = response.apparent_encoding\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        tables = soup.find_all('table', id=lambda x: x and x.endswith('-game-basic'))\n",
    "        for table in tables:\n",
    "          caption = table.find('caption')\n",
    "          team_name = caption.text.split(' Basic and Advanced Stats Table')[0].strip()\n",
    "          rows = table.find('tbody').find_all('tr')\n",
    "          for row in rows:\n",
    "            if row.find('th').text in ['Team Totals', 'Reserves']:\n",
    "              continue\n",
    "            player_name = normalize_name(row.find('th').text.strip())\n",
    "            dnp = row.find('td', {'data-stat': 'reason'})\n",
    "\n",
    "            stats = [date, player_name, team_name]\n",
    "\n",
    "            if dnp and 'Did Not Play' in dnp.text:\n",
    "              stats += ['DNP'] * (len(df_columns) - 3)\n",
    "            else:\n",
    "              for td in row.find_all('td'):\n",
    "                stat = td.text.strip()\n",
    "                stats.append(stat if stat else 0)\n",
    "  \n",
    "            if len(stats) == len(df_columns):\n",
    "              new_row = pd.DataFrame([stats], columns=df_columns)\n",
    "              stat_df = pd.concat([stat_df, new_row], ignore_index=True)\n",
    "            else:\n",
    "              print(f'Skipping incomplete data for {player_name}')\n",
    "\n",
    "        print(f'Finished Scraping: {link}')\n",
    "\n",
    "      except HTTPError as http_err:\n",
    "        if response.status_code == 429:\n",
    "          print(f'Rate limit exceeded for {link}, Status code: {response.status_code}')\n",
    "          print(f'Retry-After: {response.headers.get('Retry-After')}')\n",
    "          time.sleep(int(response.get('Retry-After'), 60))\n",
    "        else:\n",
    "          print(f'HTTP error occurred: {http_err}')\n",
    "        error = {'URL': link, 'Error': f'HTTPError: {http_err}'}\n",
    "        new_row = pd.DataFrame([error])\n",
    "        error_df = pd.concat([error_df, new_row], ignore_index=True)\n",
    "\n",
    "      except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        print(f\"Exception Type: {type(e).__name__}\")\n",
    "        error_message = str(e) if str(e) else \"No error message provided.\"\n",
    "        print(f'Error Scraping: {link}')\n",
    "        error = {'URL': link, 'Error': error_message}\n",
    "        new_row = pd.DataFrame([error])\n",
    "        error_df = pd.concat([error_df, new_row], ignore_index=True)\n",
    "      \n",
    "      delay = random.uniform(3, 7)\n",
    "      print(f\"Delaying for {delay:.2f} seconds\")\n",
    "      time.sleep(delay)\n",
    "\n",
    "  stat_df.to_csv(f'Season({season}).csv', lineterminator='\\n', index=False)\n",
    "  error_df.to_csv(f'Errors_Season({season}).csv', lineterminator='\\n', index=False)\n",
    "  \n",
    "  message = f'Saved game stats for the {season} season to a csv'\n",
    "  print(message)\n",
    "\n",
    "      \n",
    "def normalize_name(name):\n",
    "    normalized = unicodedata.normalize('NFKD', name)\n",
    "    without_diacritics = ''.join(c for c in normalized if not unicodedata.combining(c))\n",
    "    return without_diacritics.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Los Angeles Lakers\n",
      "Denver Nuggets\n",
      "\n",
      "Found tables for the teams:\n",
      "Los Angeles Lakers\n",
      "Denver Nuggets\n"
     ]
    }
   ],
   "source": [
    "def get_team_tables(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    # Dictionary to store tables for each team\n",
    "    team_tables = {}\n",
    "    \n",
    "    # Find all tables with the class \"sortable stats_table now_sortable\"\n",
    "    tables = soup.find_all('table', id=lambda x: x and x.endswith('-game-basic'))\n",
    "    \n",
    "    # Loop through the tables and store them based on the team name in the caption\n",
    "    for table in tables:\n",
    "      caption = table.find('caption')\n",
    "      if caption:\n",
    "        team_name = caption.text.split(\" Basic and Advanced Stats Table\")[0].strip()\n",
    "        print(team_name)\n",
    "        team_tables[team_name] = table\n",
    "    \n",
    "    if team_tables:\n",
    "      print(\"\\nFound tables for the teams:\")\n",
    "      for team, table in team_tables.items():\n",
    "        print(f\"{team}\")\n",
    "        # pprint(table)\n",
    "    else:\n",
    "      print(\"No tables found for the teams.\")\n",
    "    \n",
    "    return team_tables\n",
    "\n",
    "# Call the function with the given URL\n",
    "url = \"https://www.basketball-reference.com/boxscores/202310240DEN.html\"\n",
    "team_tables = get_team_tables(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2022-23 Season Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Links for each calendar month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of months along with urls for each\n",
    "season_22_23 = 'https://www.basketball-reference.com/leagues/NBA_2023_games.html'\n",
    "month_link_list, season_22_23 = get_month_links(season_22_23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Season: {season_22_23}')\n",
    "pprint(month_link_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Box score links and dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get box score link for each calendar month\n",
    "box_scores, dates = get_box_score_links(month_link_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(box_scores)\n",
    "pprint(dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Extract player stats for 22-23 season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 1/9\n",
      "https://www.basketball-reference.com/boxscores/202210180BOS.html\n",
      "20221018\n",
      "Currently Scraping https://www.basketball-reference.com/boxscores/202210180BOS.html\n",
      "Finished Scraping: https://www.basketball-reference.com/boxscores/202210180BOS.html\n",
      "Delaying for 6.30 seconds\n",
      "https://www.basketball-reference.com/boxscores/202210180GSW.html\n",
      "20221018\n",
      "Currently Scraping https://www.basketball-reference.com/boxscores/202210180GSW.html\n",
      "Finished Scraping: https://www.basketball-reference.com/boxscores/202210180GSW.html\n",
      "Delaying for 4.52 seconds\n",
      "https://www.basketball-reference.com/boxscores/202210190DET.html\n",
      "20221019\n",
      "Currently Scraping https://www.basketball-reference.com/boxscores/202210190DET.html\n",
      "Finished Scraping: https://www.basketball-reference.com/boxscores/202210190DET.html\n",
      "Delaying for 3.19 seconds\n",
      "https://www.basketball-reference.com/boxscores/202210190IND.html\n",
      "20221019\n",
      "Currently Scraping https://www.basketball-reference.com/boxscores/202210190IND.html\n",
      "Finished Scraping: https://www.basketball-reference.com/boxscores/202210190IND.html\n",
      "Delaying for 4.61 seconds\n",
      "https://www.basketball-reference.com/boxscores/202210190ATL.html\n",
      "20221019\n",
      "Currently Scraping https://www.basketball-reference.com/boxscores/202210190ATL.html\n",
      "Finished Scraping: https://www.basketball-reference.com/boxscores/202210190ATL.html\n",
      "Delaying for 5.62 seconds\n",
      "https://www.basketball-reference.com/boxscores/202210190BRK.html\n",
      "20221019\n",
      "Currently Scraping https://www.basketball-reference.com/boxscores/202210190BRK.html\n",
      "Skipping incomplete data for jaxson hayes\n",
      "Finished Scraping: https://www.basketball-reference.com/boxscores/202210190BRK.html\n",
      "Delaying for 6.02 seconds\n",
      "https://www.basketball-reference.com/boxscores/202210190MEM.html\n",
      "20221019\n",
      "Currently Scraping https://www.basketball-reference.com/boxscores/202210190MEM.html\n",
      "Finished Scraping: https://www.basketball-reference.com/boxscores/202210190MEM.html\n",
      "Delaying for 4.05 seconds\n",
      "https://www.basketball-reference.com/boxscores/202210190MIA.html\n",
      "20221019\n",
      "Currently Scraping https://www.basketball-reference.com/boxscores/202210190MIA.html\n",
      "Finished Scraping: https://www.basketball-reference.com/boxscores/202210190MIA.html\n",
      "Delaying for 4.04 seconds\n",
      "https://www.basketball-reference.com/boxscores/202210190TOR.html\n",
      "20221019\n",
      "Currently Scraping https://www.basketball-reference.com/boxscores/202210190TOR.html\n",
      "Finished Scraping: https://www.basketball-reference.com/boxscores/202210190TOR.html\n",
      "Delaying for 5.66 seconds\n",
      "https://www.basketball-reference.com/boxscores/202210190MIN.html\n",
      "20221019\n",
      "Currently Scraping https://www.basketball-reference.com/boxscores/202210190MIN.html\n",
      "Finished Scraping: https://www.basketball-reference.com/boxscores/202210190MIN.html\n",
      "Delaying for 6.65 seconds\n",
      "https://www.basketball-reference.com/boxscores/202210190SAS.html\n",
      "20221019\n",
      "Currently Scraping https://www.basketball-reference.com/boxscores/202210190SAS.html\n",
      "Finished Scraping: https://www.basketball-reference.com/boxscores/202210190SAS.html\n",
      "Delaying for 5.60 seconds\n",
      "https://www.basketball-reference.com/boxscores/202210190UTA.html\n",
      "20221019\n",
      "Currently Scraping https://www.basketball-reference.com/boxscores/202210190UTA.html\n",
      "Finished Scraping: https://www.basketball-reference.com/boxscores/202210190UTA.html\n",
      "Delaying for 4.67 seconds\n",
      "https://www.basketball-reference.com/boxscores/202210190PHO.html\n",
      "20221019\n",
      "Currently Scraping https://www.basketball-reference.com/boxscores/202210190PHO.html\n",
      "Finished Scraping: https://www.basketball-reference.com/boxscores/202210190PHO.html\n",
      "Delaying for 4.98 seconds\n",
      "https://www.basketball-reference.com/boxscores/202210190SAC.html\n",
      "20221019\n",
      "Currently Scraping https://www.basketball-reference.com/boxscores/202210190SAC.html\n",
      "Finished Scraping: https://www.basketball-reference.com/boxscores/202210190SAC.html\n",
      "Delaying for 5.84 seconds\n",
      "https://www.basketball-reference.com/boxscores/202210200PHI.html\n",
      "20221020\n",
      "Currently Scraping https://www.basketball-reference.com/boxscores/202210200PHI.html\n",
      "Finished Scraping: https://www.basketball-reference.com/boxscores/202210200PHI.html\n",
      "Delaying for 3.71 seconds\n",
      "https://www.basketball-reference.com/boxscores/202210200LAL.html\n",
      "20221020\n",
      "Currently Scraping https://www.basketball-reference.com/boxscores/202210200LAL.html\n",
      "Finished Scraping: https://www.basketball-reference.com/boxscores/202210200LAL.html\n",
      "Delaying for 3.99 seconds\n",
      "https://www.basketball-reference.com/boxscores/202210210CHO.html\n",
      "20221021\n",
      "Currently Scraping https://www.basketball-reference.com/boxscores/202210210CHO.html\n",
      "Finished Scraping: https://www.basketball-reference.com/boxscores/202210210CHO.html\n",
      "Delaying for 3.20 seconds\n",
      "https://www.basketball-reference.com/boxscores/202210210IND.html\n",
      "20221021\n",
      "Currently Scraping https://www.basketball-reference.com/boxscores/202210210IND.html\n",
      "Finished Scraping: https://www.basketball-reference.com/boxscores/202210210IND.html\n",
      "Delaying for 4.73 seconds\n",
      "https://www.basketball-reference.com/boxscores/202210210WAS.html\n",
      "20221021\n",
      "Currently Scraping https://www.basketball-reference.com/boxscores/202210210WAS.html\n",
      "Finished Scraping: https://www.basketball-reference.com/boxscores/202210210WAS.html\n",
      "Delaying for 6.18 seconds\n",
      "https://www.basketball-reference.com/boxscores/202210210ATL.html\n",
      "20221021\n",
      "Currently Scraping https://www.basketball-reference.com/boxscores/202210210ATL.html\n",
      "Finished Scraping: https://www.basketball-reference.com/boxscores/202210210ATL.html\n",
      "Delaying for 4.86 seconds\n",
      "https://www.basketball-reference.com/boxscores/202210210BRK.html\n",
      "20221021\n",
      "Currently Scraping https://www.basketball-reference.com/boxscores/202210210BRK.html\n",
      "Finished Scraping: https://www.basketball-reference.com/boxscores/202210210BRK.html\n",
      "Delaying for 6.70 seconds\n",
      "https://www.basketball-reference.com/boxscores/202210210MIA.html\n",
      "20221021\n",
      "Currently Scraping https://www.basketball-reference.com/boxscores/202210210MIA.html\n",
      "Finished Scraping: https://www.basketball-reference.com/boxscores/202210210MIA.html\n",
      "Delaying for 6.72 seconds\n",
      "https://www.basketball-reference.com/boxscores/202210210NYK.html\n",
      "20221021\n",
      "Currently Scraping https://www.basketball-reference.com/boxscores/202210210NYK.html\n",
      "Finished Scraping: https://www.basketball-reference.com/boxscores/202210210NYK.html\n",
      "Delaying for 4.61 seconds\n",
      "https://www.basketball-reference.com/boxscores/202210210HOU.html\n",
      "20221021\n",
      "Currently Scraping https://www.basketball-reference.com/boxscores/202210210HOU.html\n",
      "Finished Scraping: https://www.basketball-reference.com/boxscores/202210210HOU.html\n",
      "Delaying for 5.12 seconds\n",
      "https://www.basketball-reference.com/boxscores/202210210MIN.html\n",
      "20221021\n",
      "Currently Scraping https://www.basketball-reference.com/boxscores/202210210MIN.html\n",
      "Finished Scraping: https://www.basketball-reference.com/boxscores/202210210MIN.html\n",
      "Delaying for 6.53 seconds\n"
     ]
    }
   ],
   "source": [
    "# TODO extract player stats from each box score for 22-23 season BUG fix dataframe error\n",
    "extract_player_data(box_scores, dates, season_22_23)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2023-24 Season Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO get 2023-24 season data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rate Limit Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response Status Code: 200\n"
     ]
    }
   ],
   "source": [
    "\n",
    "start_url = 'https://www.basketball-reference.com/leagues/NBA_2023_games.html'\n",
    "\n",
    "# Function to make a request with rate limit handling\n",
    "def get_response_with_backoff(url):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 429:\n",
    "            retry_after = response.headers.get('Retry-After')\n",
    "            if retry_after:\n",
    "                retry_after = int(retry_after)\n",
    "                print(f\"Rate limit exceeded. Retry after {retry_after} seconds.\")\n",
    "                for remaining in range(retry_after, 0, -1):\n",
    "                    print(f'Retrying in {remaining} seconds...', end='\\r')\n",
    "                    time.sleep(1)\n",
    "                print('Retrying now...')\n",
    "            else:\n",
    "                retry_after = 60\n",
    "                print(\"Rate limit exceeded. Retrying after a default 60 seconds.\")\n",
    "                for remaining in range(retry_after, 0, -1):\n",
    "                    print(f'Retrying in {remaining} seconds...', end='\\r')\n",
    "                    time.sleep(1)\n",
    "                print('Retrying now...')\n",
    "            return get_response_with_backoff(url)\n",
    "        elif response.status_code == 200:\n",
    "            return response\n",
    "        else:\n",
    "            print(f\"Received unexpected status code: {response.status_code}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None\n",
    "\n",
    "# Call the function\n",
    "response = get_response_with_backoff(start_url)\n",
    "if response:\n",
    "    print(f\"Response Status Code: {response.status_code}\")\n",
    "else:\n",
    "    print(\"Failed to fetch the URL.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nba-fantasy-points-prediction-xiPMqUvC-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
